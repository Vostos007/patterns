# Quick Start - KPS

**–ù–∞—á–Ω–∏—Ç–µ —Ä–∞–±–æ—Ç–∞—Ç—å —Å KPS –∑–∞ 5 –º–∏–Ω—É—Ç!**

---

## –®–∞–≥ 1: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ (1 –º–∏–Ω—É—Ç–∞)

```bash
cd dev/PDF_PARSER_2.0
pip install -r requirements.txt

# –ù–∞—Å—Ç—Ä–æ–∏—Ç—å API –∫–ª—é—á–∏
export OPENAI_API_KEY="sk-..."
# –∏–ª–∏
export ANTHROPIC_API_KEY="sk-ant-..."
```

---

## –®–∞–≥ 2: –ü—Ä–æ—Å—Ç–µ–π—à–∏–π –ø–µ—Ä–µ–≤–æ–¥ (2 –º–∏–Ω—É—Ç—ã)

### –í–∞—Ä–∏–∞–Ω—Ç 1: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

```python
from kps.core import UnifiedPipeline

# 1. –°–æ–∑–¥–∞—Ç—å pipeline
pipeline = UnifiedPipeline()

# 2. –ü–µ—Ä–µ–≤–µ—Å—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç
result = pipeline.process("pattern.pdf", target_languages=["en", "fr"])

# 3. –ì–æ—Ç–æ–≤–æ!
print(f"–£—Å–ø–µ—Ö: {result.success}")
print(f"–í—ã—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã: {result.output_files}")
```

**–ß—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ:**
- ‚úÖ –¢–µ–∫—Å—Ç –∏–∑–≤–ª–µ—á—ë–Ω –∏–∑ PDF (AI Docling –∏–ª–∏ PyMuPDF)
- ‚úÖ –ü–µ—Ä–µ–≤–µ–¥—ë–Ω —Å –≥–ª–æ—Å—Å–∞—Ä–∏–µ–º (ru ‚Üí en, ru ‚Üí fr)
- ‚úÖ –°–∏—Å—Ç–µ–º–∞ —Å–∞–º–æ–æ–±—É—á–∏–ª–∞—Å—å (—Å–æ—Ö—Ä–∞–Ω–∏–ª–∞ –≤ –ø–∞–º—è—Ç—å)
- ‚úÖ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –≤ PDF –∏ IDML
- ‚úÖ –§–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ `output/`

### –í–∞—Ä–∏–∞–Ω—Ç 2: –ü–æ—à–∞–≥–æ–≤—ã–π (–∫–æ–Ω—Ç—Ä–æ–ª—å)

```python
from kps.core import UnifiedPipeline, PipelineConfig, ExtractionMethod

# –ù–∞—Å—Ç—Ä–æ–∏—Ç—å
config = PipelineConfig(
    extraction_method=ExtractionMethod.DOCLING,  # AI extraction
    enable_few_shot=True,                        # –°–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ
    enable_auto_suggestions=True                 # –ê–≤—Ç–æ–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
)

# –°–æ–∑–¥–∞—Ç—å
pipeline = UnifiedPipeline(config)

# –û–±—Ä–∞–±–æ—Ç–∞—Ç—å
result = pipeline.process("document.pdf", ["en"])

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å
print(f"Cache hit rate: {result.cache_hit_rate:.0%}")
print(f"Translation stats: {result.translation_stats}")
```

---

## –®–∞–≥ 3: –î–æ–±–∞–≤–∏—Ç—å –±–∞–∑—É –∑–Ω–∞–Ω–∏–π (2 –º–∏–Ω—É—Ç—ã)

### –°–æ–∑–¥–∞—Ç—å –±–∞–∑—É –∑–Ω–∞–Ω–∏–π

```python
from kps.knowledge import KnowledgeBase

# 1. –°–æ–∑–¥–∞—Ç—å –±–∞–∑—É
kb = KnowledgeBase("data/knowledge.db")

# 2. –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã
kb.ingest_folder("knowledge/", recursive=True)
# ‚Üí –°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–∞–∑–æ–±—å—ë—Ç –Ω–∞ —Å–µ–∫—Ü–∏–∏,
#   –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä—É–µ—Ç, —Å–æ–∑–¥–∞—Å—Ç embeddings

# 3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å
stats = kb.get_statistics()
print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ: {stats['total_entries']} —Å–µ–∫—Ü–∏–π")
print(f"–ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º: {stats['by_category']}")
```

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å pipeline

```python
from kps.core import UnifiedPipeline
from kps.knowledge import KnowledgeBase

# –°–æ–∑–¥–∞—Ç—å –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
kb = KnowledgeBase("data/knowledge.db")
kb.ingest_folder("knowledge/", recursive=True)

# –°–æ–∑–¥–∞—Ç—å pipeline
pipeline = UnifiedPipeline()

# –ü–æ–¥–∫–ª—é—á–∏—Ç—å –±–∞–∑—É –∑–Ω–∞–Ω–∏–π (–¥–ª—è RAG)
pipeline.translator.knowledge_base = kb

# –¢–µ–ø–µ—Ä—å –ø–µ—Ä–µ–≤–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç RAG!
result = pipeline.process("document.pdf", ["en"])

# –°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:
# ‚úÖ –ò—â–µ—Ç –ø–æ—Ö–æ–∂–∏–µ –ø—Ä–∏–º–µ—Ä—ã –≤ –±–∞–∑–µ
# ‚úÖ –î–æ–±–∞–≤–ª—è–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∫ –ø—Ä–æ–º–ø—Ç—É AI
# ‚úÖ –ü–æ–ª—É—á–∞–µ—Ç –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥!
```

---

## –ü—Ä–∏–º–µ—Ä—ã

### –ü—Ä–∏–º–µ—Ä 1: –ë–∞–∑–æ–≤—ã–π –ø–µ—Ä–µ–≤–æ–¥

```python
from kps.core import UnifiedPipeline

pipeline = UnifiedPipeline()
result = pipeline.process("pattern.pdf", ["en", "fr"])

if result.success:
    print("‚úÖ –ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≤–µ—Ä—à—ë–Ω!")
    print(f"–§–∞–π–ª—ã: {result.output_files}")
else:
    print(f"‚ùå –û—à–∏–±–∫–∞: {result.error}")
```

### –ü—Ä–∏–º–µ—Ä 2: –° –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏

```python
from kps.core import UnifiedPipeline, PipelineConfig
from kps.core import ExtractionMethod, MemoryType

config = PipelineConfig(
    extraction_method=ExtractionMethod.DOCLING,  # AI extraction
    memory_type=MemoryType.SEMANTIC,             # Semantic memory
    enable_few_shot=True,                        # Few-shot learning
    output_formats=["pdf", "idml"]               # Output formats
)

pipeline = UnifiedPipeline(config)
result = pipeline.process("document.pdf", ["en"])
```

### –ü—Ä–∏–º–µ—Ä 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞

```python
from kps.core import UnifiedPipeline

pipeline = UnifiedPipeline()

# –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫
result1 = pipeline.process("document.pdf", ["en"])
print(f"Cache hit: {result1.cache_hit_rate:.0%}")  # 0%

# –í—Ç–æ—Ä–æ–π –∑–∞–ø—É—Å–∫ (—Ç–æ—Ç –∂–µ –¥–æ–∫—É–º–µ–Ω—Ç)
result2 = pipeline.process("document.pdf", ["en"])
print(f"Cache hit: {result2.cache_hit_rate:.0%}")  # 90%+!
```

### –ü—Ä–∏–º–µ—Ä 4: –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π

```python
from kps.knowledge import KnowledgeBase

# –°–æ–∑–¥–∞—Ç—å
kb = KnowledgeBase("data/knowledge.db")

# –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã
kb.ingest_folder("knowledge/books/", recursive=True)
kb.ingest_folder("knowledge/patterns/", recursive=True)

# –ü–æ–∏—Å–∫
results = kb.search("–∫–∞–∫ –≤—è–∑–∞—Ç—å –∫–æ—Å—ã", limit=5)
for r in results:
    print(f"- {r.title} ({r.category.value})")

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
stats = kb.get_statistics()
print(f"\n–í—Å–µ–≥–æ: {stats['total_entries']} –∑–∞–ø–∏—Å–µ–π")
print("–ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
for cat, count in stats['by_category'].items():
    print(f"  {cat}: {count}")
```

---

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫

```
dev/PDF_PARSER_2.0/
‚îú‚îÄ‚îÄ data/                    # –î–∞–Ω–Ω—ã–µ
‚îÇ   ‚îú‚îÄ‚îÄ knowledge.db        # –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π
‚îÇ   ‚îú‚îÄ‚îÄ memory.db           # Translation memory
‚îÇ   ‚îî‚îÄ‚îÄ glossary.json       # –ì–ª–æ—Å—Å–∞—Ä–∏–π
‚îÇ
‚îú‚îÄ‚îÄ knowledge/               # –î–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ patterns/           # –£–∑–æ—Ä—ã
‚îÇ   ‚îú‚îÄ‚îÄ techniques/         # –¢–µ—Ö–Ω–∏–∫–∏
‚îÇ   ‚îú‚îÄ‚îÄ yarns/              # –ü—Ä—è–∂–∞
‚îÇ   ‚îî‚îÄ‚îÄ projects/           # –ì–æ—Ç–æ–≤—ã–µ –ø—Ä–æ–µ–∫—Ç—ã
‚îÇ
‚îú‚îÄ‚îÄ input/                   # –í—Ö–æ–¥–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
‚îÇ   ‚îî‚îÄ‚îÄ pattern.pdf
‚îÇ
‚îî‚îÄ‚îÄ output/                  # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    ‚îú‚îÄ‚îÄ pattern_EN/
    ‚îÇ   ‚îú‚îÄ‚îÄ pattern_EN.pdf
    ‚îÇ   ‚îî‚îÄ‚îÄ pattern_EN.idml
    ‚îî‚îÄ‚îÄ pattern_FR/
        ‚îú‚îÄ‚îÄ pattern_FR.pdf
        ‚îî‚îÄ‚îÄ pattern_FR.idml
```

---

## –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### API –∫–ª—é—á–∏

```bash
# OpenAI
export OPENAI_API_KEY="sk-..."

# Anthropic Claude (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞)
export ANTHROPIC_API_KEY="sk-ant-..."
```

### –ü—É—Ç–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

```bash
export GLOSSARY_PATH="data/glossary.json"
export MEMORY_DB_PATH="data/memory.db"
export KNOWLEDGE_DB_PATH="data/knowledge.db"
```

---

## Troubleshooting

### –ü—Ä–æ–±–ª–µ–º–∞: –ú–æ–¥—É–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã

```bash
pip install -r requirements.txt
```

### –ü—Ä–æ–±–ª–µ–º–∞: API –∫–ª—é—á –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç

```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –∫–ª—é—á —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω
echo $OPENAI_API_KEY

# –ï—Å–ª–∏ –ø—É—Å—Ç–æ:
export OPENAI_API_KEY="sk-..."
```

### –ü—Ä–æ–±–ª–µ–º–∞: –ú–µ–¥–ª–µ–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥

```python
# –í–∫–ª—é—á–∏—Ç—å semantic memory –¥–ª—è –∫—ç—à–∞
from kps.core import PipelineConfig, MemoryType

config = PipelineConfig(
    memory_type=MemoryType.SEMANTIC,  # –í–∫–ª—é—á–∏—Ç—å –∫—ç—à
    enable_few_shot=True               # Few-shot learning
)

pipeline = UnifiedPipeline(config)
```

### –ü—Ä–æ–±–ª–µ–º–∞: –ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ

```python
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –¥–ª—è RAG
kb = KnowledgeBase("data/knowledge.db")
kb.ingest_folder("knowledge/", recursive=True)

pipeline.translator.knowledge_base = kb
# ‚Üí –¢–µ–ø–µ—Ä—å –ø–µ—Ä–µ–≤–æ–¥—ã —Ç–æ—á–Ω–µ–µ!
```

---

## –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

1. **–ò–∑—É—á–∏—Ç—å –ø—Ä–∏–º–µ—Ä—ã:**
   ```bash
   python examples/unified_pipeline_example.py
   python examples/knowledge_base_example.py
   ```

2. **–ü—Ä–æ—á–∏—Ç–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é:**
   - [UNIFIED_PIPELINE.md](./docs/UNIFIED_PIPELINE.md) - –ü–æ–ª–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ
   - [KNOWLEDGE_BASE.md](./docs/KNOWLEDGE_BASE.md) - –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π
   - [SELF_LEARNING_TRANSLATION.md](./docs/SELF_LEARNING_TRANSLATION.md) - –°–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ

3. **–ù–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–æ–¥ —Å–µ–±—è:**
   - –î–æ–±–∞–≤–∏—Ç—å —Å–≤–æ–π –≥–ª–æ—Å—Å–∞—Ä–∏–π
   - –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
   - –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é pipeline

---

## –ö–æ–º–∞–Ω–¥—ã –¥–ª—è –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞
cd dev/PDF_PARSER_2.0
pip install -r requirements.txt
export OPENAI_API_KEY="sk-..."

# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–º–µ—Ä–∞
python -c "
from kps.core import UnifiedPipeline

pipeline = UnifiedPipeline()
result = pipeline.process('input/pattern.pdf', ['en', 'fr'])
print(f'–£—Å–ø–µ—Ö: {result.success}')
print(f'–§–∞–π–ª—ã: {result.output_files}')
"

# –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
python -c "
from kps.knowledge import KnowledgeBase

kb = KnowledgeBase('data/knowledge.db')
kb.ingest_folder('knowledge/', recursive=True)

stats = kb.get_statistics()
print(f'–ó–∞–≥—Ä—É–∂–µ–Ω–æ: {stats[\"total_entries\"]} –∑–∞–ø–∏—Å–µ–π')
"
```

---

## –ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

- [README.md](./README.md) - –û–±–∑–æ—Ä —Å–∏—Å—Ç–µ–º—ã
- [UNIFIED_PIPELINE.md](./docs/UNIFIED_PIPELINE.md) - –ì–ª–∞–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞
- [KNOWLEDGE_BASE.md](./docs/KNOWLEDGE_BASE.md) - –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π
- [SECTION_SPLITTING.md](./docs/SECTION_SPLITTING.md) - –£–º–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ
- [CONTEXT_AWARE_CHUNKING.md](./docs/CONTEXT_AWARE_CHUNKING.md) - RAG —Å overlap
- [SELF_LEARNING_TRANSLATION.md](./docs/SELF_LEARNING_TRANSLATION.md) - –°–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ

---

**–ì–æ—Ç–æ–≤–æ! –í—ã –∑–∞–ø—É—Å—Ç–∏–ª–∏ KPS –∑–∞ 5 –º–∏–Ω—É—Ç!** üéâ

**–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥:** –ò–∑—É—á–∏—Ç–µ [UNIFIED_PIPELINE.md](./docs/UNIFIED_PIPELINE.md) –¥–ª—è —É–≥–ª—É–±–ª—ë–Ω–Ω–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã.
