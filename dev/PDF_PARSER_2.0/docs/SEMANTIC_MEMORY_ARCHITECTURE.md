# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –ø–∞–º—è—Ç–∏ –ø–µ—Ä–µ–≤–æ–¥–æ–≤

## –û–±–∑–æ—Ä

–î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≥–æ, –∫–∞–∫ –∏ –∫—É–¥–∞ –∑–∞–ø–∏—Å—ã–≤–∞—é—Ç—Å—è –¥–∞–Ω–Ω—ã–µ, –∫–∞–∫ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ, –∏ –∫–∞–∫ —Å–∏—Å—Ç–µ–º–∞ –ø–æ–Ω–∏–º–∞–µ—Ç —á—Ç–æ –≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è.

---

## 1. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö

### 1.1 –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö (SQLite)

```
data/
‚îî‚îÄ‚îÄ semantic_memory.db
    ‚îú‚îÄ‚îÄ translations        # –û—Å–Ω–æ–≤–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø–µ—Ä–µ–≤–æ–¥–æ–≤
    ‚îú‚îÄ‚îÄ term_suggestions    # –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Ç–µ—Ä–º–∏–Ω–æ–≤
    ‚îî‚îÄ‚îÄ [indexes]           # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
```

### 1.2 –¢–∞–±–ª–∏—Ü–∞ `translations`

```sql
CREATE TABLE translations (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    hash TEXT UNIQUE NOT NULL,              -- MD5 —Ö–µ—à –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
    source_text TEXT NOT NULL,              -- –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
    translated_text TEXT NOT NULL,          -- –ü–µ—Ä–µ–≤–æ–¥
    source_lang TEXT NOT NULL,              -- –Ø–∑—ã–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ (ru, en, fr)
    target_lang TEXT NOT NULL,              -- –¶–µ–ª–µ–≤–æ–π —è–∑—ã–∫
    glossary_terms TEXT,                    -- JSON: ["k2tog", "row"]
    timestamp REAL NOT NULL,                -- –ö–æ–≥–¥–∞ –¥–æ–±–∞–≤–ª–µ–Ω–æ
    usage_count INTEGER DEFAULT 1,          -- –°–∫–æ–ª—å–∫–æ —Ä–∞–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–æ—Å—å
    quality_score REAL DEFAULT 1.0,         -- –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ 0.0-1.0
    embedding BLOB,                         -- –í–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ (384 float32)
    context TEXT,                           -- –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    created_at REAL DEFAULT (datetime('now'))
);
```

**–ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞:**
```sql
CREATE INDEX idx_hash ON translations(hash);                    -- O(1) —Ç–æ—á–Ω—ã–π –ø–æ–∏—Å–∫
CREATE INDEX idx_lang_pair ON translations(source_lang, target_lang);  -- –§–∏–ª—å—Ç—Ä –ø–æ —è–∑—ã–∫–∞–º
CREATE INDEX idx_usage ON translations(usage_count DESC);       -- –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ
CREATE INDEX idx_quality ON translations(quality_score DESC);   -- –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ
```

### 1.3 –¢–∞–±–ª–∏—Ü–∞ `term_suggestions`

```sql
CREATE TABLE term_suggestions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    source_text TEXT NOT NULL,
    translated_text TEXT,
    source_lang TEXT NOT NULL,
    target_lang TEXT NOT NULL,
    frequency INTEGER DEFAULT 1,            -- –ö–∞–∫ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è
    confidence REAL DEFAULT 0.5,            -- –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏
    contexts TEXT,                          -- JSON: ["context1", "context2"]
    UNIQUE(source_text, source_lang, target_lang)
);
```

---

## 2. Embeddings - –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è

### 2.1 –ß—Ç–æ —Ç–∞–∫–æ–µ embeddings?

**Embedding** - —ç—Ç–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ –º–Ω–æ–≥–æ–º–µ—Ä–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ (–æ–±—ã—á–Ω–æ 384 –∏–ª–∏ 768 –∏–∑–º–µ—Ä–µ–Ω–∏–π).

```python
–¢–µ–∫—Å—Ç: "–ü—Ä–æ–≤—è–∂–∏—Ç–µ 2 –ø–µ—Ç–ª–∏ –≤–º–µ—Å—Ç–µ"
‚Üì
Embedding: [0.12, -0.34, 0.56, ..., 0.78]  # 384 —á–∏—Å–ª–∞
```

**–ö–ª—é—á–µ–≤–æ–µ —Å–≤–æ–π—Å—Ç–≤–æ:** –ü–æ—Ö–æ–∂–∏–µ –ø–æ —Å–º—ã—Å–ª—É —Ç–µ–∫—Å—Ç—ã –∏–º–µ—é—Ç –ø–æ—Ö–æ–∂–∏–µ embeddings!

```
"–ü—Ä–æ–≤—è–∂–∏—Ç–µ 2 –ø–µ—Ç–ª–∏ –≤–º–µ—Å—Ç–µ"     ‚Üí  [0.12, -0.34, ...]
"–ü—Ä–æ–≤—è–∂–∏—Ç–µ –¥–≤–µ –ø–µ—Ç–ª–∏ –≤–º–µ—Å—Ç–µ"   ‚Üí  [0.13, -0.35, ...]  ‚Üê –û—á–µ–Ω—å –±–ª–∏–∑–∫–æ!
"–ó–∞–∫—Ä–æ–π—Ç–µ –≤—Å–µ –ø–µ—Ç–ª–∏"            ‚Üí  [0.45, 0.21, ...]   ‚Üê –î–∞–ª–µ–∫–æ
```

### 2.2 –ö–∞–∫ —Å–æ–∑–¥–∞—é—Ç—Å—è embeddings

**–í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è):**
```python
from sentence_transformers import SentenceTransformer

# –ú–Ω–æ–≥–æ—è–∑—ã—á–Ω–∞—è –º–æ–¥–µ–ª—å (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç 50+ —è–∑—ã–∫–æ–≤)
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

text = "–ü—Ä–æ–≤—è–∂–∏—Ç–µ 2 –ø–µ—Ç–ª–∏ –≤–º–µ—Å—Ç–µ"
embedding = model.encode(text)  # ‚Üí numpy array [384]
```

**–ú–æ–¥–µ–ª–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á:**
| –ú–æ–¥–µ–ª—å | –†–∞–∑–º–µ—Ä | –°–∫–æ—Ä–æ—Å—Ç—å | –¢–æ—á–Ω–æ—Å—Ç—å | –Ø–∑—ã–∫–∏ |
|--------|--------|----------|----------|-------|
| `paraphrase-multilingual-MiniLM-L12-v2` | 384d | –ë—ã—Å—Ç—Ä–æ | –•–æ—Ä–æ—à–æ | 50+ |
| `distiluse-base-multilingual-cased-v2` | 512d | –°—Ä–µ–¥–Ω–µ | –û—Ç–ª–∏—á–Ω–æ | 50+ |
| `LaBSE` | 768d | –ú–µ–¥–ª–µ–Ω–Ω–æ | –õ—É—á—à–µ–µ | 109 |

**–í —Ç–µ–∫—É—â–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ (—É–ø—Ä–æ—â—ë–Ω–Ω–∞—è —Å–∏–º—É–ª—è—Ü–∏—è):**
```python
def _get_embedding(self, text: str, lang: str) -> np.ndarray:
    # –•–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –¥–µ–º–æ
    hash_bytes = hashlib.sha256(text.lower().encode()).digest()
    embedding = np.frombuffer(hash_bytes, dtype=np.uint8)
    embedding = np.tile(embedding, (384 // len(embedding) + 1))[:384]
    return embedding.astype(np.float32) / 255.0
```

### 2.3 –•—Ä–∞–Ω–µ–Ω–∏–µ embeddings

**–§–æ—Ä–º–∞—Ç:** BLOB (Binary Large Object) –≤ SQLite
```python
# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
embedding: np.ndarray [384]  # float32
‚Üí embedding.tobytes()        # ‚Üí bytes
‚Üí SQLite BLOB

# –ó–∞–≥—Ä—É–∑–∫–∞
SQLite BLOB
‚Üí np.frombuffer(data, dtype=np.float32)  # ‚Üí np.ndarray [384]
```

**–†–∞–∑–º–µ—Ä:** 384 √ó 4 bytes (float32) = **1.5 KB –Ω–∞ –∑–∞–ø–∏—Å—å**

---

## 3. –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫

### 3.1 –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ

–î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è embeddings –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è **–∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ**:

```
similarity = cos(Œ∏) = (A ¬∑ B) / (||A|| √ó ||B||)

–≥–¥–µ:
- A, B - –≤–µ–∫—Ç–æ—Ä—ã embeddings
- ¬∑ - —Å–∫–∞–ª—è—Ä–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ
- || || - –Ω–æ—Ä–º–∞ –≤–µ–∫—Ç–æ—Ä–∞
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** —á–∏—Å–ª–æ –æ—Ç -1.0 –¥–æ 1.0
- 1.0 = –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ
- 0.0 = –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω—ã–µ (–Ω–∏–∫–∞–∫ –Ω–µ —Å–≤—è–∑–∞–Ω—ã)
- -1.0 = –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω—ã–µ

**–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ 0.0-1.0:**
```python
similarity_normalized = (similarity + 1.0) / 2.0
```

### 3.2 –ê–ª–≥–æ—Ä–∏—Ç–º –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö

```python
def find_similar(query_text, threshold=0.85, limit=5):
    # 1. –ü–æ–ª—É—á–∏—Ç—å embedding –∑–∞–ø—Ä–æ—Å–∞
    query_emb = get_embedding(query_text)  # [384]

    # 2. –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –∑–∞–ø–∏—Å–∏ –¥–ª—è —è–∑—ã–∫–æ–≤–æ–π –ø–∞—Ä—ã
    candidates = db.query("""
        SELECT * FROM translations
        WHERE source_lang = ? AND target_lang = ?
        AND embedding IS NOT NULL
        ORDER BY usage_count DESC
        LIMIT 1000  -- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –Ω–µ –≤–µ—Å—å –¥–∞—Ç–∞—Å–µ—Ç
    """)

    # 3. –í—ã—á–∏—Å–ª–∏—Ç—å —Å—Ö–æ–¥—Å—Ç–≤–æ —Å –∫–∞–∂–¥–æ–π
    results = []
    for candidate in candidates:
        candidate_emb = load_embedding(candidate)  # [384]
        similarity = cosine_similarity(query_emb, candidate_emb)

        if similarity >= threshold:  # –ü–æ—Ä–æ–≥ 85%
            results.append((candidate, similarity))

    # 4. –°–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ —Å—Ö–æ–¥—Å—Ç–≤—É –∏ –≤–µ—Ä–Ω—É—Ç—å —Ç–æ–ø-N
    results.sort(key=lambda x: x[1], reverse=True)
    return results[:limit]
```

### 3.3 –ü—Ä–∏–º–µ—Ä—ã –ø–æ–∏—Å–∫–∞

**–í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç:**
```
"–ü—Ä–æ–≤—è–∂–∏—Ç–µ –¥–≤–µ –ø–µ—Ç–ª–∏ –≤–º–µ—Å—Ç–µ –ª–∏—Ü–µ–≤–æ–π"
```

**–ù–∞–π–¥–µ–Ω–Ω—ã–µ –ø–æ—Ö–æ–∂–∏–µ (—Å –æ—Ü–µ–Ω–∫–æ–π —Å—Ö–æ–¥—Å—Ç–≤–∞):**

| –°—Ö–æ–¥—Å—Ç–≤–æ | –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç | –ü–µ—Ä–µ–≤–æ–¥ |
|----------|----------------|---------|
| 100% | –ü—Ä–æ–≤—è–∂–∏—Ç–µ –¥–≤–µ –ø–µ—Ç–ª–∏ –≤–º–µ—Å—Ç–µ –ª–∏—Ü–µ–≤–æ–π | Knit two stitches together |
| 94% | –ü—Ä–æ–≤—è–∂–∏—Ç–µ 2 –ø–µ—Ç–ª–∏ –≤–º–µ—Å—Ç–µ –ª–∏—Ü–µ–≤–æ–π | Knit 2 stitches together |
| 91% | –ü—Ä–æ–≤—è–∂–∏—Ç–µ 2 –ª–∏—Ü –≤–º–µ—Å—Ç–µ | K2tog |
| 87% | –í—è–∂–∏—Ç–µ –¥–≤–µ –ø–µ—Ç–ª–∏ –≤–º–µ—Å—Ç–µ | Knit two together |
| 83% | –ü—Ä–æ–≤—è–∑–∞—Ç—å 2 –ø–µ—Ç–ª–∏ –ª–∏—Ü–µ–≤–æ–π | Knit 2 stitches |

**–ù–µ –Ω–∞–π–¥–µ–Ω—ã (—Å—Ö–æ–¥—Å—Ç–≤–æ < 85%):**
- "–ó–∞–∫—Ä–æ–π—Ç–µ –≤—Å–µ –ø–µ—Ç–ª–∏" (43% - –¥—Ä—É–≥–∞—è —Ç–µ–º–∞)
- "–°–¥–µ–ª–∞–π—Ç–µ –Ω–∞–∫–∏–¥" (31% - —Å–æ–≤—Å–µ–º –¥—Ä—É–≥–æ–µ)

---

## 4. RAG (Retrieval-Augmented Generation)

### 4.1 –ß—Ç–æ —Ç–∞–∫–æ–µ RAG?

**RAG** = Retrieval (–ø–æ–∏—Å–∫) + Augmented (–¥–æ–ø–æ–ª–Ω–µ–Ω–Ω–∞—è) + Generation (–≥–µ–Ω–µ—Ä–∞—Ü–∏—è)

**–ò–¥–µ—è:** –ü–µ—Ä–µ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –æ—Ç–≤–µ—Ç–∞ –ò–ò, —Å–Ω–∞—á–∞–ª–∞ –Ω–∞–π—Ç–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.

```
–ó–∞–ø—Ä–æ—Å: "–í—è–∂–∏—Ç–µ –ª–∏—Ü–µ–≤—ã–º–∏ –¥–æ –∫–æ–Ω—Ü–∞ —Ä—è–¥–∞"
    ‚Üì
1. RETRIEVAL - –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –≤ –±–∞–∑–µ:
   - "–í—è–∂–∏—Ç–µ –ª–∏—Ü–µ–≤—ã–º–∏" ‚Üí "Knit" (92%)
   - "–¥–æ –∫–æ–Ω—Ü–∞ —Ä—è–¥–∞" ‚Üí "to end of row" (89%)
   - "–ü—Ä–æ–≤—è–∂–∏—Ç–µ —Ä—è–¥ –ª–∏—Ü–µ–≤—ã–º–∏" ‚Üí "Knit row" (87%)
    ‚Üì
2. AUGMENT - –î–æ–±–∞–≤–∏—Ç—å –≤ –ø—Ä–æ–º–ø—Ç –ò–ò:
   "
   –ü–µ—Ä–µ–≤–µ–¥–∏ —Å —É—á—ë—Ç–æ–º —ç—Ç–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤:
   - –í—è–∂–∏—Ç–µ –ª–∏—Ü–µ–≤—ã–º–∏ ‚Üí Knit
   - –¥–æ –∫–æ–Ω—Ü–∞ —Ä—è–¥–∞ ‚Üí to end of row
   - –ü—Ä–æ–≤—è–∂–∏—Ç–µ —Ä—è–¥ –ª–∏—Ü–µ–≤—ã–º–∏ ‚Üí Knit row

   –¢–µ–ø–µ—Ä—å –ø–µ—Ä–µ–≤–µ–¥–∏: –í—è–∂–∏—Ç–µ –ª–∏—Ü–µ–≤—ã–º–∏ –¥–æ –∫–æ–Ω—Ü–∞ —Ä—è–¥–∞
   "
    ‚Üì
3. GENERATION - –ò–ò –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º:
   "Knit to end of row" ‚úì (—Ç–æ—á–Ω—ã–π –∏ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–π!)
```

### 4.2 –†–µ–∞–ª–∏–∑–∞—Ü–∏—è RAG

```python
def get_rag_examples(query_text, source_lang, target_lang, limit=5):
    """
    –ü–æ–ª—É—á–∏—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞.
    """
    # 1. –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö
    similar = find_similar(
        query_text,
        source_lang,
        target_lang,
        threshold=0.70,  # 70%+ —Å—Ö–æ–¥—Å—Ç–≤–∞
        limit=limit
    )

    # 2. –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
    examples = []
    for entry, similarity in similar:
        examples.append((
            entry.source_text,
            entry.translated_text,
            similarity
        ))

    return examples

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
examples = memory.get_rag_examples("–í—è–∂–∏—Ç–µ –ª–∏—Ü–µ–≤—ã–º–∏", "ru", "en", limit=3)

# –î–æ–±–∞–≤–∏—Ç—å –≤ –ø—Ä–æ–º–ø—Ç
context = "–ü—Ä–∏–º–µ—Ä—ã –ø–µ—Ä–µ–≤–æ–¥–æ–≤:\n"
for source, target, sim in examples:
    context += f"- {source} ‚Üí {target} ({sim:.0%} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å)\n"

# –ü–µ—Ä–µ–¥–∞—Ç—å –ò–ò –≤–º–µ—Å—Ç–µ —Å –≥–ª–æ—Å—Å–∞—Ä–∏–µ–º
translator.translate(segments, glossary_context=glossary + context)
```

### 4.3 –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ RAG

‚úì **–ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å:** –ò–ò –≤–∏–¥–∏—Ç –∫–∞–∫ –º—ã –ø–µ—Ä–µ–≤–æ–¥–∏–ª–∏ —Ä–∞–Ω—å—à–µ
‚úì **–ö–æ–Ω—Ç–µ–∫—Å—Ç:** –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –ø–æ–º–æ–≥–∞—é—Ç –ø–æ–Ω—è—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏–∫—É
‚úì **–ö–∞—á–µ—Å—Ç–≤–æ:** –ú–µ–Ω—å—à–µ –æ—à–∏–±–æ–∫, –±–æ–ª—å—à–µ —Ç–æ—á–Ω–æ—Å—Ç–∏
‚úì **–û–±—É—á–µ–Ω–∏–µ:** –°–∏—Å—Ç–µ–º–∞ —É—á–∏—Ç—Å—è –Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

---

## 5. –ö–∞–∫ —Å–∏—Å—Ç–µ–º–∞ –ø–æ–Ω–∏–º–∞–µ—Ç —á—Ç–æ –≥–¥–µ –ª–µ–∂–∏—Ç?

### 5.1 –¢—Ä—ë—Ö—É—Ä–æ–≤–Ω–µ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
–£–†–û–í–ï–ù–¨ 1: In-Memory Cache (RAM)
‚îú‚îÄ‚îÄ cache: Dict[hash, Entry]           # –ì–æ—Ä—è—á–∏–µ –¥–∞–Ω–Ω—ã–µ
‚îú‚îÄ‚îÄ embedding_cache: Dict[text, Vec]   # –ö—ç—à –≤–µ–∫—Ç–æ—Ä–æ–≤
‚îî‚îÄ‚îÄ –°–∫–æ—Ä–æ—Å—Ç—å: <1ms

–£–†–û–í–ï–ù–¨ 2: SQLite –ë–∞–∑–∞ (–î–∏—Å–∫)
‚îú‚îÄ‚îÄ translations (—Å –∏–Ω–¥–µ–∫—Å–∞–º–∏)
‚îú‚îÄ‚îÄ term_suggestions
‚îî‚îÄ‚îÄ –°–∫–æ—Ä–æ—Å—Ç—å: 1-10ms

–£–†–û–í–ï–ù–¨ 3: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫
‚îú‚îÄ‚îÄ –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (–ë–î)
‚îú‚îÄ‚îÄ –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ö–æ–¥—Å—Ç–≤–∞ (CPU)
‚îî‚îÄ‚îÄ –°–∫–æ—Ä–æ—Å—Ç—å: 10-100ms
```

### 5.2 –ü–æ—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –ø–æ–∏—Å–∫–µ

```python
def get_translation(text, source_lang, target_lang):
    """
    –°—Ç—Ä–∞—Ç–µ–≥–∏—è –ø–æ–∏—Å–∫–∞ (3 —É—Ä–æ–≤–Ω—è):
    """
    # –£–†–û–í–ï–ù–¨ 1: –¢–æ—á–Ω—ã–π –ø–æ–∏—Å–∫ –≤ RAM –∫—ç—à–µ
    hash_key = md5(f"{source_lang}:{target_lang}:{text.lower()}")
    if hash_key in memory_cache:
        return memory_cache[hash_key]  # ‚ö° <1ms

    # –£–†–û–í–ï–ù–¨ 2: –¢–æ—á–Ω—ã–π –ø–æ–∏—Å–∫ –≤ –ë–î –ø–æ –∏–Ω–¥–µ–∫—Å—É
    entry = db.query("""
        SELECT * FROM translations
        WHERE hash = ?
    """, hash_key)
    if entry:
        memory_cache[hash_key] = entry  # –î–æ–±–∞–≤–∏—Ç—å –≤ –∫—ç—à
        return entry  # ‚ö° 1-5ms

    # –£–†–û–í–ï–ù–¨ 3: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫
    if use_embeddings:
        similar = find_similar(text, source_lang, target_lang, threshold=0.85)
        if similar:
            return similar[0]  # ‚ö° 10-50ms

    # –ù–µ –Ω–∞–π–¥–µ–Ω–æ - –Ω—É–∂–µ–Ω –Ω–æ–≤—ã–π –ø–µ—Ä–µ–≤–æ–¥
    return None
```

### 5.3 –ö–∞—Ä—Ç–∞ –∑–Ω–∞–Ω–∏–π —Å–∏—Å—Ç–µ–º—ã

```
translations (100,000 –∑–∞–ø–∏—Å–µ–π)
‚îÇ
‚îú‚îÄ [–ò–ù–î–ï–ö–°–´] –ë—ã—Å—Ç—Ä—ã–π –¥–æ—Å—Ç—É–ø
‚îÇ  ‚îú‚îÄ hash ‚Üí O(1) —Ç–æ—á–Ω—ã–π –ø–æ–∏—Å–∫
‚îÇ  ‚îú‚îÄ (source_lang, target_lang) ‚Üí O(log N) —Ñ–∏–ª—å—Ç—Ä
‚îÇ  ‚îú‚îÄ usage_count DESC ‚Üí –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –ø–µ—Ä–≤—ã–º–∏
‚îÇ  ‚îî‚îÄ quality_score DESC ‚Üí –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–µ—Ä–≤—ã–º–∏
‚îÇ
‚îú‚îÄ [CACHE] –¢–æ–ø-1000 –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –≤ RAM
‚îÇ  ‚îî‚îÄ –°–∫–æ—Ä–æ—Å—Ç—å: <1ms
‚îÇ
‚îî‚îÄ [EMBEDDINGS] –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫
   ‚îú‚îÄ –í–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ 384D
   ‚îú‚îÄ –ö–ª–∞—Å—Ç–µ—Ä—ã –ø–æ—Ö–æ–∂–∏—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤
   ‚îî‚îÄ –°–∫–æ—Ä–æ—Å—Ç—å: 10-50ms –¥–ª—è 1000 –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
```

---

## 6. –°–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ - –∫–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç

### 6.1 –¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ –¶–ò–ö–õ –°–ê–ú–û–û–ë–£–ß–ï–ù–ò–Ø                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

1. –ü–ï–†–ï–í–û–î –ù–û–í–û–ì–û –¢–ï–ö–°–¢–ê
   ‚îú‚îÄ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫—ç—à (—Ç–æ—á–Ω—ã–π + –ø–æ—Ö–æ–∂–∏–µ)
   ‚îú‚îÄ –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ (‚â•85% —Å—Ö–æ–¥—Å—Ç–≤–∞) ‚Üí –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
   ‚îî‚îÄ –ï—Å–ª–∏ –Ω–µ—Ç ‚Üí –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ —á–µ—Ä–µ–∑ –ò–ò
        ‚Üì
2. –°–û–•–†–ê–ù–ï–ù–ò–ï –í –ü–ê–ú–Ø–¢–¨
   ‚îú‚îÄ –°–æ–∑–¥–∞—Ç—å embedding —Ç–µ–∫—Å—Ç–∞
   ‚îú‚îÄ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –ë–î (translations)
   ‚îú‚îÄ –î–æ–±–∞–≤–∏—Ç—å –≤ cache (–µ—Å–ª–∏ –ø–æ–ø—É–ª—è—Ä–Ω–æ)
   ‚îî‚îÄ usage_count = 1, quality_score = 1.0
        ‚Üì
3. RAG –î–õ–Ø –°–õ–ï–î–£–Æ–©–ò–• –ü–ï–†–ï–í–û–î–û–í
   ‚îú‚îÄ –ù–æ–≤—ã–π —Ç–µ–∫—Å—Ç ‚Üí –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö
   ‚îú‚îÄ –ù–∞–π–¥–µ–Ω—ã ‚Üí –¥–æ–±–∞–≤–∏—Ç—å –∫–∞–∫ –ø—Ä–∏–º–µ—Ä—ã –≤ –ø—Ä–æ–º–ø—Ç
   ‚îî‚îÄ –ò–ò —É—á–∏—Ç—Å—è –Ω–∞ —ç—Ç–∏—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö
        ‚Üì
4. –û–ë–ù–û–í–õ–ï–ù–ò–ï –°–¢–ê–¢–ò–°–¢–ò–ö–ò
   ‚îú‚îÄ –ü—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏: usage_count++
   ‚îú‚îÄ –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: quality_score = avg(old, new)
   ‚îî‚îÄ –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –∑–∞–ø–∏—Å–∏ –ø–æ–¥–Ω–∏–º–∞—é—Ç—Å—è –≤ –∫—ç—à
        ‚Üì
5. –ê–í–¢–û-–ü–†–ï–î–õ–û–ñ–ï–ù–ò–Ø –¢–ï–†–ú–ò–ù–û–í
   ‚îú‚îÄ –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —á–∞—Å—Ç—ã—Ö —Ñ—Ä–∞–∑
   ‚îú‚îÄ frequency ‚â• 3 ‚Üí –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –≤ –≥–ª–æ—Å—Å–∞—Ä–∏–π
   ‚îî‚îÄ –ü–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –≥–ª–æ—Å—Å–∞—Ä–∏—è –¥–∞–Ω–Ω—ã–º–∏
        ‚Üì
        ‚îî‚îÄ‚îÄ> –í–û–ó–í–†–ê–¢ –ö –®–ê–ì–£ 1 (—É–ª—É—á—à–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞!)
```

### 6.2 –ü—Ä–∏–º–µ—Ä –ø—Ä–æ–≥—Ä–µ—Å—Å–∞

**–î–µ–Ω—å 1: –ü–µ—Ä–≤—ã–π –ø–µ—Ä–µ–≤–æ–¥**
```
Input: "–ü—Ä–æ–≤—è–∂–∏—Ç–µ 2 –ø–µ—Ç–ª–∏ –≤–º–µ—Å—Ç–µ"
Cache: MISS (–Ω–∏—á–µ–≥–æ –Ω–µ—Ç)
Action: –ü–µ—Ä–µ–≤–µ—Å—Ç–∏ —á–µ—Ä–µ–∑ –ò–ò ‚Üí "Knit 2 stitches together"
Save: hash ‚Üí translation + embedding
RAG: –ù–µ—Ç –ø—Ä–∏–º–µ—Ä–æ–≤
Cost: $0.001
```

**–î–µ–Ω—å 3: –ü–æ—Ö–æ–∂–∏–π —Ç–µ–∫—Å—Ç**
```
Input: "–ü—Ä–æ–≤—è–∂–∏—Ç–µ –¥–≤–µ –ø–µ—Ç–ª–∏ –≤–º–µ—Å—Ç–µ"
Cache: MISS (—Ç–æ—á–Ω–æ–≥–æ –Ω–µ—Ç)
Semantic: FOUND! "–ü—Ä–æ–≤—è–∂–∏—Ç–µ 2 –ø–µ—Ç–ª–∏ –≤–º–µ—Å—Ç–µ" (94% —Å—Ö–æ–¥—Å—Ç–≤–∞)
Action: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—ç—à
Cost: $0.000 (–±–µ—Å–ø–ª–∞—Ç–Ω–æ!)
Bonus: usage_count++ –¥–ª—è –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
```

**–ù–µ–¥–µ–ª—è 2: –ù–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç**
```
Input: "–í—è–∂–∏—Ç–µ –ª–∏—Ü–µ–≤—ã–º–∏ –¥–æ –∫–æ–Ω—Ü–∞"
Cache: MISS
Semantic: –ù–∞–π–¥–µ–Ω—ã 3 –ø–æ—Ö–æ–∂–∏—Ö (75-85%)
RAG: –î–æ–±–∞–≤–∏—Ç—å –ø—Ä–∏–º–µ—Ä—ã –≤ –ø—Ä–æ–º–ø—Ç:
     - "–ü—Ä–æ–≤—è–∂–∏—Ç–µ 2 –ø–µ—Ç–ª–∏ –≤–º–µ—Å—Ç–µ" ‚Üí "Knit 2 stitches together"
     - "–í—è–∂–∏—Ç–µ –ª–∏—Ü–µ–≤—ã–º–∏" ‚Üí "Knit"
     - "–¥–æ –∫–æ–Ω—Ü–∞ —Ä—è–¥–∞" ‚Üí "to end of row"
Action: –ò–ò –ø–µ—Ä–µ–≤–æ–¥–∏—Ç –° –ö–û–ù–¢–ï–ö–°–¢–û–ú ‚Üí –ª—É—á—à–µ –∫–∞—á–µ—Å—Ç–≤–æ!
Result: "Knit to end" (–∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–π —Å—Ç–∏–ª—å)
Cost: $0.001 (–Ω–æ –∫–∞—á–µ—Å—Ç–≤–æ –≤—ã—à–µ!)
```

**–ú–µ—Å—è—Ü 2: –°–∏—Å—Ç–µ–º–∞ –æ–±—É—á–∏–ª–∞—Å—å**
```
Database: 5000 –∑–∞–ø–∏—Å–µ–π
Cache: 1000 –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –≤ RAM
Embeddings: –ü–ª–æ—Ç–Ω—ã–µ –∫–ª–∞—Å—Ç–µ—Ä—ã –ø–æ—Ö–æ–∂–∏—Ö —Ñ—Ä–∞–∑
Cache Hit Rate: 65% (—Ç–æ—á–Ω—ã–µ + —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ)
Quality: +7% —É–ª—É—á—à–µ–Ω–∏–µ vs –Ω–∞—á–∞–ª–æ
Cost: -65% —ç–∫–æ–Ω–æ–º–∏—è
RAG Examples: –í —Å—Ä–µ–¥–Ω–µ–º 3-5 —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –Ω–∞ –∑–∞–ø—Ä–æ—Å
```

---

## 7. –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è

### 7.1 –°–∫–æ—Ä–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞

| –ú–µ—Ç–æ–¥ | –î–∞–Ω–Ω—ã—Ö | –°–∫–æ—Ä–æ—Å—Ç—å | –¢–æ—á–Ω–æ—Å—Ç—å |
|-------|--------|----------|----------|
| RAM Cache (hash) | 1000 | <1ms | –¢–æ–ª—å–∫–æ —Ç–æ—á–Ω—ã–µ |
| DB Index (hash) | 100K | 1-5ms | –¢–æ–ª—å–∫–æ —Ç–æ—á–Ω—ã–µ |
| DB Index (lang pair) | 100K | 5-20ms | –¢–æ–ª—å–∫–æ —Ç–æ—á–Ω—ã–µ |
| Semantic (embeddings) | 1000 | 10-50ms | –¢–æ—á–Ω—ã–µ + –ø–æ—Ö–æ–∂–∏–µ |
| Semantic (embeddings) | 10K | 50-200ms | –¢–æ—á–Ω—ã–µ + –ø–æ—Ö–æ–∂–∏–µ |

### 7.2 –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

**1. –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤**
```sql
-- –ù–µ –≤–µ—Å—å –¥–∞—Ç–∞—Å–µ—Ç, –∞ —Ç–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–µ
SELECT * FROM translations
WHERE source_lang = ? AND target_lang = ?
AND embedding IS NOT NULL
ORDER BY usage_count DESC, quality_score DESC
LIMIT 1000  -- –¢–æ–ª—å–∫–æ —Ç–æ–ø-1000
```

**2. –î–≤—É—Ö—ç—Ç–∞–ø–Ω—ã–π –ø–æ–∏—Å–∫**
```python
# –≠—Ç–∞–ø 1: –¢–æ—á–Ω—ã–π –ø–æ–∏—Å–∫ (–±—ã—Å—Ç—Ä—ã–π)
exact = get_by_hash(text)  # 1ms
if exact: return exact

# –≠—Ç–∞–ø 2: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π (–º–µ–¥–ª–µ–Ω–Ω–µ–µ, –Ω–æ —É–º–Ω–µ–µ)
similar = find_similar(text, threshold=0.85)  # 50ms
if similar: return similar[0]
```

**3. –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ embeddings**
```python
embedding_cache = {}  # In-memory

def get_embedding(text):
    if text in embedding_cache:
        return embedding_cache[text]  # –ú–≥–Ω–æ–≤–µ–Ω–Ω–æ!

    emb = model.encode(text)  # –î–æ—Ä–æ–≥–æ: 10-20ms
    embedding_cache[text] = emb
    return emb
```

### 7.3 –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ

| –ó–∞–ø–∏—Å–µ–π | RAM Cache | DB Size | Semantic Search | Cache Hit |
|---------|-----------|---------|----------------|-----------|
| 1K | 1.5 MB | 2 MB | 10ms | 40% |
| 10K | 15 MB | 20 MB | 50ms | 55% |
| 100K | 15 MB | 200 MB | 50ms | 65% |
| 1M | 15 MB | 2 GB | 100ms | 75% |

**–í—ã–≤–æ–¥:** –°–∏—Å—Ç–µ–º–∞ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç—Å—è –¥–æ –º–∏–ª–ª–∏–æ–Ω–æ–≤ –∑–∞–ø–∏—Å–µ–π!

---

## 8. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å–∏—Å—Ç–µ–º–æ–π –ø–µ—Ä–µ–≤–æ–¥–∞

### 8.1 Workflow —Å semantic memory

```python
from kps.translation import GlossaryTranslator
from kps.translation.semantic_memory import SemanticTranslationMemory

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
orchestrator = TranslationOrchestrator()
glossary = GlossaryManager()
glossary.load_from_yaml("glossary.yaml")

# –£–º–Ω–∞—è –ø–∞–º—è—Ç—å —Å embeddings
memory = SemanticTranslationMemory(
    db_path="data/semantic_memory.db",
    use_embeddings=True,
    embedding_cache_size=1000
)

# –ü–µ—Ä–µ–≤–æ–¥—á–∏–∫ —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º –ø–æ–∏—Å–∫–æ–º
translator = GlossaryTranslator(
    orchestrator,
    glossary,
    memory=memory,  # ‚Üê –£–º–Ω–∞—è –ø–∞–º—è—Ç—å –≤–º–µ—Å—Ç–æ –ø—Ä–æ—Å—Ç–æ–π!
    enable_few_shot=True,
    enable_auto_suggestions=True
)

# –ü–µ—Ä–µ–≤–æ–¥ —Å —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ–º
result = translator.translate(segments, "en")

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
print(f"–ò–∑ –∫—ç—à–∞ (—Ç–æ—á–Ω—ã–µ): {result.cached_exact}")
print(f"–ò–∑ –∫—ç—à–∞ (–ø–æ—Ö–æ–∂–∏–µ): {result.cached_similar}")
print(f"RAG –ø—Ä–∏–º–µ—Ä–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {result.rag_examples_used}")
```

### 8.2 –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º

| –§—É–Ω–∫—Ü–∏—è | –ü—Ä–æ—Å—Ç–∞—è –ø–∞–º—è—Ç—å | –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –ø–∞–º—è—Ç—å |
|---------|---------------|---------------------|
| –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ | ‚úì Hash (MD5) | ‚úì Hash (MD5) |
| –ü–æ—Ö–æ–∂–∏–µ —Ñ—Ä–∞–∑—ã | ‚úó | ‚úì Embeddings + cosine |
| RAG –ø—Ä–∏–º–µ—Ä—ã | ‚úó | ‚úì Top-K –ø–æ—Ö–æ–∂–∏—Ö |
| –°–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ | –ë–∞–∑–æ–≤–æ–µ | –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–µ |
| –°–∫–æ—Ä–æ—Å—Ç—å (—Ç–æ—á–Ω—ã–µ) | <1ms | <1ms |
| –°–∫–æ—Ä–æ—Å—Ç—å (–ø–æ—Ö–æ–∂–∏–µ) | N/A | 10-50ms |
| –•—Ä–∞–Ω–µ–Ω–∏–µ | JSON (–ø—Ä–æ—Å—Ç–æ–π) | SQLite + BLOB |
| –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ | –î–æ 10K | –î–æ 1M+ |

---

## 9. –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

### –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã

1. **–¢—Ä—ë—Ö—É—Ä–æ–≤–Ω–µ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:** RAM ‚Üí DB ‚Üí Semantic
2. **Embeddings:** –í–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å–º—ã—Å–ª–∞
3. **–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫:** –ù–∞—Ö–æ–¥–∏—Ç –ø–æ—Ö–æ–∂–∏–µ, –Ω–µ —Ç–æ–ª—å–∫–æ —Ç–æ—á–Ω—ã–µ
4. **RAG:** Retrieval-Augmented Generation –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
5. **–°–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ:** –°–∏—Å—Ç–µ–º–∞ —É–ª—É—á—à–∞–µ—Ç—Å—è —Å –∫–∞–∂–¥—ã–º –ø–µ—Ä–µ–≤–æ–¥–æ–º

### –ß—Ç–æ –¥–∞–ª—å—à–µ?

–î–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω-–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è:

1. **Sentence-BERT:** –ó–∞–º–µ–Ω–∏—Ç—å —Å–∏–º—É–ª—è—Ü–∏—é –Ω–∞ —Ä–µ–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
   ```bash
   pip install sentence-transformers
   ```

2. **–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –±–∞–∑–∞:** –í–º–µ—Å—Ç–æ SQLite –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å vector DB
   - [Qdrant](https://qdrant.tech/) - –±—ã—Å—Ç—Ä—ã–π vector search
   - [Weaviate](https://weaviate.io/) - —Å –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º semantic search
   - [Pinecone](https://www.pinecone.io/) - managed cloud service

3. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥:** –û—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏

4. **A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ:** –°—Ä–∞–≤–Ω–∏–≤–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥—ã —Å/–±–µ–∑ RAG

---

**–°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –∏ –±—É–¥–µ—Ç —É–ª—É—á—à–∞—Ç—å—Å—è —Å –∫–∞–∂–¥—ã–º –ø–µ—Ä–µ–≤–æ–¥–æ–º!** üöÄ
